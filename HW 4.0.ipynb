{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poitrew11/Young-Yandex-homeworks/blob/main/HW%204.0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision.datasets import FashionMNIST\n",
        "\n",
        "# __________start of block__________\n",
        "\n",
        "def args_and_kwargs(*args, **kwargs):\n",
        "    return args, kwargs\n",
        "\n",
        "def parse_pytorch_model(model_str):\n",
        "    def parse_layer(layer_str):\n",
        "        layer_name, params = layer_str.split(\"(\", 1)\n",
        "        layer_info = {\"type\": layer_name.strip()}\n",
        "        params_template = layer_str.replace(layer_name, \"args_and_kwargs\")\n",
        "\n",
        "        param_dict = {}\n",
        "        if len(params):\n",
        "            args, kwargs = eval(params_template)\n",
        "            if len(args) or len(kwargs):\n",
        "                param_dict[\"args\"] = args\n",
        "                for name, value in kwargs.items():\n",
        "                    param_dict[name] = value\n",
        "        layer_info[\"parameters\"] = param_dict\n",
        "        return layer_info\n",
        "\n",
        "    model_dict = {}\n",
        "    lines = model_str.splitlines()\n",
        "    model_name = lines[0].strip(\"()\")\n",
        "    model_dict[\"model_name\"] = model_name\n",
        "    model_dict[\"layers\"] = []\n",
        "\n",
        "    layer_regex = re.compile(r\"\\((\\d+)\\): (.+)\")\n",
        "    for line in lines[1:]:\n",
        "        line = line.strip()\n",
        "        match = layer_regex.match(line)\n",
        "        if match:\n",
        "            index, layer = match.groups()\n",
        "            model_dict[\"layers\"].append({\"index\": int(index), \"layer\": parse_layer(layer)})\n",
        "    return model_dict\n",
        "\n",
        "# __________end of block__________"
      ],
      "metadata": {
        "id": "TV-RywwMSO4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "def get_predictions(model, eval_data, step=10):\n",
        "\n",
        "    predicted_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx in range(0, len(eval_data), step):\n",
        "            y_predicted = model(eval_data[idx : idx + step].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    predicted_labels = \",\".join([str(x.item()) for x in list(predicted_labels)])\n",
        "    return predicted_labels\n",
        "\n",
        "\n",
        "def get_accuracy(model, data_loader):\n",
        "    predicted_labels = []\n",
        "    real_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            y_predicted = model(batch[0].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "            real_labels.append(batch[1])\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    real_labels = torch.cat(real_labels)\n",
        "    accuracy_score = (predicted_labels == real_labels).type(torch.FloatTensor).mean()\n",
        "    return accuracy_score\n"
      ],
      "metadata": {
        "id": "IICcmh2RVQ9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict -O hw_overfitting_data_dict.npy\n",
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZW7rBARXje6",
        "outputId": "b05fe2b6-10b7-4e20-ab93-fa995df7d2f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-21 07:53:55--  https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict [following]\n",
            "--2025-04-21 07:53:56--  https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6272446 (6.0M) [application/octet-stream]\n",
            "Saving to: ‘hw_overfitting_data_dict.npy’\n",
            "\n",
            "hw_overfitting_data 100%[===================>]   5.98M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2025-04-21 07:53:56 (66.1 MB/s) - ‘hw_overfitting_data_dict.npy’ saved [6272446/6272446]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cpu')\n",
        "train_fmnist_data = FashionMNIST('.', transform = torchvision.transforms.ToTensor(), train = True, download = True)\n",
        "test_fmnist_data = FashionMNIST('.', train = False, transform = torchvision.transforms.ToTensor(), download = True)\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(train_fmnist_data, batch_size = 32, shuffle = True)\n",
        "test_data_loader = torch.utils.data.DataLoader(test_fmnist_data, shuffle = False, batch_size = 32)\n",
        "\n",
        "random_batch = next(iter(train_data_loader))\n",
        "\n",
        "_image, _label = random_batch[0][0], random_batch[1][0]\n",
        "plt.figure()\n",
        "plt.imshow(_image.reshape(28, 28))\n",
        "plt.title(f\"Image label: {_label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "8MH0HJ7QgGQW",
        "outputId": "a3b21cbd-b385-44c3-c1e5-2e9ac3e99934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 18.9MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 298kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 5.55MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 7.83MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Image label: 0')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SimpleCNN, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 16, kernel_size = 3, padding = 1)\n",
        "    self.conv2 = nn.Conv2d(16, 32, kernel_size = 3, padding = 1)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.fc1 = nn.Linear(32 * 7 * 7, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = self.pool(x)\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = self.pool(x)\n",
        "    x = x.view(-1, 32 * 7 * 7)\n",
        "    x = self.fc1(x)\n",
        "    return x\n",
        "\n",
        "model_task_1 = SimpleCNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_task_1.parameters(), lr = 0.003)\n",
        "\n",
        "def train_model(model, train_loader, test_loader, epochs=5):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        accuracy = 100 * correct / total\n",
        "        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}, '\n",
        "              f'Test Accuracy: {accuracy:.2f}%')\n",
        "train_model(model_task_1, train_data_loader, test_data_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zloIJHSCkIGQ",
        "outputId": "776e713c-0aa1-4288-be72-6e21f161ccc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.4126, Test Accuracy: 87.87%\n",
            "Epoch 2, Loss: 0.2856, Test Accuracy: 89.27%\n",
            "Epoch 3, Loss: 0.2538, Test Accuracy: 89.94%\n",
            "Epoch 4, Loss: 0.2348, Test Accuracy: 90.13%\n",
            "Epoch 5, Loss: 0.2216, Test Accuracy: 90.48%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_task_1.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHx-pxIWrLS7",
        "outputId": "d7edf6a0-8c85-4f4e-ce1a-36d8c15321ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleCNN(\n",
              "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=1568, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert model_task_1 is not None, \"Please, use `model_task_1` variable to store your model\"\n",
        "\n",
        "try:\n",
        "    x = random_batch[0].to(device)\n",
        "    y = random_batch[1].to(device)\n",
        "\n",
        "    # compute outputs given inputs, both are variables\n",
        "    y_predicted = model_task_1(x)\n",
        "except Exception as e:\n",
        "    print(\"Something is wrong with the model\")\n",
        "    raise e\n",
        "\n",
        "\n",
        "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
        "\n",
        "print(\"Everything seems fine!\")\n",
        "# __________end of block_________"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGxqH6NjrFTO",
        "outputId": "f710512b-56a6-4e76-f658-31d9d50b09ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything seems fine!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc_task_1 = get_accuracy(model_task_1, train_data_loader)\n",
        "print(f\"Neural network accuracy on train set: {train_acc_task_1:3.5}\")\n",
        "test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
        "print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yofJfhWrTDZ",
        "outputId": "a03533ec-c935-4b95-f983-0395999becf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.93247\n",
            "Neural network accuracy on test set: 0.9059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert test_acc_task_1 >= 0.885, \"Train accuracy is below 0.885 threshold\"\n",
        "assert (\n",
        "    train_acc_task_1 >= 0.905\n",
        "), \"Test accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\""
      ],
      "metadata": {
        "id": "f0jjCZ7src53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "loaded_data_dict = np.load(\"hw_overfitting_data_dict.npy\", allow_pickle=True)\n",
        "\n",
        "submission_dict = {\n",
        "    \"train_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
        "    ),\n",
        "    \"test_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
        "    ),\n",
        "    \"model_task_1\": parse_pytorch_model(str(model_task_1)),\n",
        "}\n",
        "\n",
        "with open(\"submission_dict_task_1.json\", \"w\") as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print(\"File saved to `submission_dict_task_1.json`\")\n",
        "# __________end of block__________"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBAreqWwrg1Y",
        "outputId": "ba936ea8-e269-4571-d189-56ecb3628349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `submission_dict_task_1.json`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "        self.conv5 = nn.Conv2d(512, 1024, kernel_size=3, padding=1)\n",
        "        self.conv6 = nn.Conv2d(1024, 2048, kernel_size=3, padding=1)\n",
        "        self.conv7 = nn.Conv2d(2048, 4096, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(4096 * 3 * 3, 2048)\n",
        "        self.fc2 = nn.Linear(2048, 512)\n",
        "        self.fc3 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = F.relu(self.conv6(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv7(x))\n",
        "        x = x.view(-1, 4096 * 3 * 3)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model_task_2 = SimpleCNNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_task_1.parameters(), lr = 0.001)"
      ],
      "metadata": {
        "id": "tu7x58I6CsOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_model(model, train_loader, test_loader, epochs=100):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        accuracy = 100 * correct / total\n",
        "        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}, '\n",
        "              f'Test Accuracy: {accuracy:.2f}%')\n",
        "model_task_2 = SimpleCNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_task_2.parameters(), lr = 0.001)\n",
        "#training_model(model_task_2, train_data_loader, test_data_loader)"
      ],
      "metadata": {
        "id": "GBYuoLVOtisI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layers_task_2 = []\n",
        "for element in parse_pytorch_model(str(model_task_2)).get(\"layers\", []):\n",
        "    layer_name = element[\"layer\"][\"type\"]\n",
        "    assert \"dropout\" not in layer_name.lower(), \"Do not use Dropout in Task 2!\"\n",
        "    assert \"batchnorm\" not in layer_name.lower(), \"Do not use BatchNorm in Task 2!\"\n",
        "    layers_task_2.append(layer_name)"
      ],
      "metadata": {
        "id": "Dl_KTmUQwz_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_task_2.to(device)\n",
        "train_acc_task_2 = get_accuracy(model_task_2, train_data_loader)\n",
        "print(f\"Neural network accuracy on train set: {train_acc_task_2:3.5}\")\n",
        "test_acc_task_2 = get_accuracy(model_task_2, test_data_loader)\n",
        "print(f\"Neural network accuracy on test set: {test_acc_task_2:3.5}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swpSx4ciw2kL",
        "outputId": "5b523ee2-b913-4f61-aea3-84285b863c7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.98833\n",
            "Neural network accuracy on test set: 0.9005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert train_acc_task_2 >= test_acc_task_2, \"Train accuracy must be higher than task accuracy\"\n",
        "assert train_acc_task_2 >= 0.88, \"Train accuracy must be higher than 0.88\"\n",
        "assert (\n",
        "    train_acc_task_2 - test_acc_task_2 >= 0.04\n",
        "), \"Test accuracy should be at least 0.04 lower that train.\""
      ],
      "metadata": {
        "id": "nj2Ir_GUzKQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "loaded_data_dict = np.load(\"hw_overfitting_data_dict.npy\", allow_pickle=True)\n",
        "\n",
        "submission_dict.update(\n",
        "    {\n",
        "        \"train_predictions_task_2\": get_predictions(\n",
        "            model_task_2, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
        "        ),\n",
        "        \"test_predictions_task_2\": get_predictions(\n",
        "            model_task_2, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
        "        ),\n",
        "        \"model_task_2\": parse_pytorch_model(str(model_task_2)),\n",
        "    }\n",
        ")\n",
        "\n",
        "with open(\"submission_dict_tasks_1_and_2.json\", \"w\") as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print(\"File saved to `submission_dict_tasks_1_and_2.json`\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8593ySUPF7p",
        "outputId": "e4049308-a5b8-4e29-d201-8784060a033e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `submission_dict_tasks_1_and_2.json`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_task_3 = SimpleCNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_task_3.parameters(), lr = 0.002)\n",
        "training_model(model_task_3, train_data_loader, test_data_loader, epochs = 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZM5L4jtRhKG",
        "outputId": "28d62294-6926-4235-95c4-e0f5388939ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.4184, Test Accuracy: 87.47%\n",
            "Epoch 2, Loss: 0.2870, Test Accuracy: 89.23%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert (\n",
        "    layers_task_2 is not None\n",
        "), \"Initializa layers_task_2 vairable which contains list of layers in task 2 model\""
      ],
      "metadata": {
        "id": "PNvN8B6VT7XF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layers_task_3 = []\n",
        "for element in parse_pytorch_model(str(model_task_3)).get(\"layers\", []):\n",
        "    layer_name = element[\"layer\"][\"type\"]\n",
        "    layers_task_3.append(layer_name)\n",
        "\n",
        "\n",
        "idx = 0\n",
        "for model_3_layer in layers_task_3:\n",
        "    model_2_layer = layers_task_2[idx]\n",
        "    if \"dropout\" not in model_3_layer.lower() and \"batchnorm\" not in model_3_layer.lower():\n",
        "        assert (\n",
        "            model_3_layer == model_2_layer\n",
        "        ), \"Models in tasks 2 and 3 must share the architecture except for Dropout and BatchNorm!\"\n",
        "        idx += 1"
      ],
      "metadata": {
        "id": "jVTigW1jT-oG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_task_3.to(device)\n",
        "train_acc_task_3 = get_accuracy(model_task_3, train_data_loader)\n",
        "print(f\"Neural network accuracy on train set: {train_acc_task_3:3.5}\")\n",
        "test_acc_task_3 = get_accuracy(model_task_3, test_data_loader)\n",
        "print(f\"Neural network accuracy on test set: {test_acc_task_3:3.5}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVbVxPTWUDoG",
        "outputId": "c97473c9-47b6-402b-ee93-ca0f351fcbfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.9069\n",
            "Neural network accuracy on test set: 0.8923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert train_acc_task_3 >= 0.88, \"Train accuracy must be higher than 0.88\"\n",
        "assert train_acc_task_3 >= 0.865, \"Test accuracy must be higher than 0.865\"\n",
        "assert (\n",
        "    train_acc_task_3 - test_acc_task_3 <= 0.015\n",
        "), \"Test accuracy should not be lower that train more than by 0.015\""
      ],
      "metadata": {
        "id": "ipVxP-wWYi4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "loaded_data_dict = np.load(\"hw_overfitting_data_dict.npy\", allow_pickle=True)\n",
        "\n",
        "submission_dict.update(\n",
        "    {\n",
        "        \"train_predictions_task_3\": get_predictions(\n",
        "            model_task_3, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
        "        ),\n",
        "        \"test_predictions_task_3\": get_predictions(\n",
        "            model_task_3, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
        "        ),\n",
        "        \"model_task_3\": parse_pytorch_model(str(model_task_3)),\n",
        "    }\n",
        ")\n",
        "\n",
        "with open(\"submission_dict_final.json\", \"w\") as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print(\"File saved to `submission_dict_final.json`\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nq99grMiaR6r",
        "outputId": "7b2a18e1-e1c7-4c36-d120-eccbe7cffd5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `submission_dict_final.json`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "N792CaPBbbqD",
        "outputId": "5c5ef075-ff6b-4a2d-ddfc-c3a2266cc6e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3baea39a-bccb-4f6a-bdb2-9a463a6826cf\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3baea39a-bccb-4f6a-bdb2-9a463a6826cf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving submission_dict_tasks_1_and_2.json to submission_dict_tasks_1_and_2.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"submission_dict_tasks_1_and_2.json\", \"r\") as f:\n",
        "    submission_dict = json.load(f)\n"
      ],
      "metadata": {
        "id": "MX8GHqDkbgJd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyO/LbJvg7mB2mnlThSS8rP9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}